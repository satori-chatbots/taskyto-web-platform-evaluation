# Taskyto Web Platform - Chatbot Evaluation Repository

This repository stores the chatbots generated from experiments conducted on the [Taskyto Web Platform](http://miso.ii.uam.es:9000). The experiments are divided into two main categories, each stored in its own directory: `UserStudy` and `PerformanceEvaluation`.

## `UserStudy` Directory

This directory contains the chatbots and related data generated by volunteer users during user studies.

Each folder within `UserStudy` is named after the user(s) who participated (e.g., `user1_and_user2`, `user3`). Inside each user folder, you will find:

-   A directory named after the chatbot created by the user. This directory contains the complete source code and configuration of the chatbot.
-   A JSON file (`chat_history_...json`) containing the full conversation history between the user and the Taskyto development assistant that led to the creation of the chatbot.

## `PerformanceEvaluation` Directory

This directory stores chatbots generated during performance tests designed to measure the platform's efficiency.

The performance evaluation was conducted using prompts of varying lengths and languages:

-   **Prompt Lengths**:
    -   5 prompts with fewer than 50 words.
    -   5 prompts with 50 to 100 words.
    -   5 prompts with 100 to 150 words.

-   **Languages**:
    -   The initial set of 15 prompts was written in Spanish.
    -   The entire process was then replicated with English translations of the same prompts.

For each of the 15 prompts in each language, three chatbots were generated to compare creation times and consistency, resulting in a total of 45 chatbots for Spanish and 45 for English (90 chatbots in total).

Inside the `PerformanceEvaluation` directory, you will find:

-   `chatbots/`: This folder contains the 90 generated chatbots, organized by prompt length and language.
-   `conversationPompts/`: This folder contains the JSON conversation files where the user provides the prompt and the assistant returns the generated chatbot content.

## Common Directory Structure

Both `UserStudy` and `PerformanceEvaluation` share a common subdirectory structure to categorize chatbots based on the length of the prompt used to generate them:

-   `shorts/`: For chatbots generated from prompts with **< 50 words**.
-   `med/`: For chatbots generated from prompts with **50-100 words**.
-   `long/`: For chatbots generated from prompts with **100-150 words**.
